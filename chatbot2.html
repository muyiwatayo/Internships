<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Voice Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0d1117;
        }
        .chat-bubble-user {
            background-color: #21262d;
            border-radius: 1rem 1rem 0 1rem;
        }
        .chat-bubble-ai {
            background-color: #1f75fe;
            border-radius: 1rem 1rem 1rem 0;
        }
        .mic-button {
            transition: all 0.3s ease;
        }
        .mic-button:hover {
            box-shadow: 0 0 15px rgba(31, 117, 254, 0.7);
        }
        .mic-button.listening {
            animation: pulse-ring 1.5s infinite;
            background-color: #ef4444;
        }
        @keyframes pulse-ring {
            0% { box-shadow: 0 0 0 0 rgba(31, 117, 254, 0.7); }
            70% { box-shadow: 0 0 0 25px rgba(31, 117, 254, 0); }
            100% { box-shadow: 0 0 0 0 rgba(31, 117, 254, 0); }
        }
    </style>
</head>
<body class="min-h-screen flex flex-col items-center p-4">

```
<header class="w-full max-w-2xl text-center mb-6">
    <h1 class="text-3xl font-bold text-white mb-2">Voice AI Chatbot (Gemini)</h1>
</header>

<main id="chatHistory" class="flex-grow w-full max-w-2xl overflow-y-auto mb-4 p-4 space-y-4 h-[60vh] md:h-[70vh] bg-gray-900 rounded-xl shadow-2xl border border-gray-700">
    <div class="p-3 text-sm text-gray-400 text-center">
        Tap the microphone to start speaking. I'm ready to chat!
    </div>
</main>

<div class="w-full max-w-md flex flex-col items-center">
    <div id="statusIndicator" class="text-sm font-medium h-6 text-gray-400 mb-4 transition-all duration-300">
        Ready
    </div>

    <button id="micButton"
        class="mic-button bg-blue-600 text-white p-6 rounded-full shadow-lg flex items-center justify-center focus:outline-none disabled:opacity-50"
        onclick="toggleListening()">
        <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-8 h-8">
            <path d="M8.25 4.5a3.75 3.75 0 1 1 7.5 0v8.25a3.75 3.75 0 1 1-7.5 0V4.5z" />
            <path d="M15.75 17.25v-2.25a5.25 5.25 0 0 0-10.5 0v2.25c0 1.991 1.838 3.657 4.125 3.868v2.087a.75.75 0 0 0 1.5 0v-2.087c2.287-.211 4.125-1.877 4.125-3.868z" />
        </svg>
        <svg id="stopIcon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-8 h-8 hidden">
            <path fill-rule="evenodd" d="M4.5 7.5a3 3 0 0 1 3-3h9a3 3 0 0 1 3 3v9a3 3 0 0 1-3 3h-9a3 3 0 0 1-3-3v-9z" clip-rule="evenodd" />
        </svg>
    </button>
</div>

<script>
    // --- Configuration ---
    const GEMINI_API_KEY = "AIzaSyD42_jX7sDkDBQaZiYqiz_R7ZuL65ykY3Q"; 
    const GEMINI_MODEL = 'gemini-2.5-flash';
    const CHAT_ENDPOINT = `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`;

    // --- UI Elements ---
    const micButton = document.getElementById('micButton');
    const micIcon = document.getElementById('micIcon');
    const stopIcon = document.getElementById('stopIcon');
    const statusIndicator = document.getElementById('statusIndicator');
    const chatHistoryDiv = document.getElementById('chatHistory');

    // --- State Variables ---
    let isListening = false;
    let recognition = null;
    let chatHistory = [];
    let isSpeaking = false;
    let isAiThinking = false;

    // --- UI Update ---
    function updateStatus(message, color='text-gray-400') {
        statusIndicator.textContent = message;
        statusIndicator.className = `text-sm font-medium h-6 mb-4 transition-all duration-300 ${color}`;
    }

    function updateMicButton(listening) {
        isListening = listening;
        micButton.classList.toggle('listening', listening);
        micIcon.classList.toggle('hidden', listening);
        stopIcon.classList.toggle('hidden', !listening);
        micButton.disabled = isAiThinking || isSpeaking;
    }

    function createChatBubble(text, sender) {
        const isUser = sender==='user';
        const bubbleDiv = document.createElement('div');
        bubbleDiv.className = `flex ${isUser?'justify-end':'justify-start'}`;
        const contentDiv = document.createElement('div');
        contentDiv.className = `max-w-xs md:max-w-lg p-3 text-sm shadow-md ${isUser?'chat-bubble-user text-white':'chat-bubble-ai text-white'}`;
        contentDiv.textContent = text;
        bubbleDiv.appendChild(contentDiv);
        chatHistoryDiv.appendChild(bubbleDiv);
        chatHistoryDiv.scrollTo({ top: chatHistoryDiv.scrollHeight, behavior: 'smooth' });
    }

    // --- Gemini API ---
    function formatHistoryForGemini() {
        return chatHistory.map(m=>({role:m.sender==='user'?'user':'model', parts:[{text:m.text}]}));
    }

    async function getGeminiResponse(userText) {
        isAiThinking = true;
        micButton.disabled = true;
        updateStatus('Gemini is thinking...', 'text-yellow-400');

        chatHistory.push({sender:'user', text:userText});
        createChatBubble(userText, 'user');

        try {
            const resp = await fetch(CHAT_ENDPOINT, {
                method:'POST',
                headers:{'Content-Type':'application/json'},
                body:JSON.stringify({contents: formatHistoryForGemini()})
            });

            if(!resp.ok) throw new Error(`API call failed: ${resp.status} ${resp.statusText}`);
            const json = await resp.json();
            const aiResponse = json.candidates?.[0]?.content?.parts?.[0]?.text || "Sorry, I couldn't generate a response.";

            chatHistory.push({sender:'ai', text:aiResponse});
            createChatBubble(aiResponse, 'ai');

            await speak(aiResponse);
        } catch(e) {
            console.error("Gemini API Error:", e);
            const errorMsg = "Error connecting to AI. Check your API key.";
            createChatBubble(errorMsg, 'ai');
            speak(errorMsg);
        } finally {
            isAiThinking = false;
            micButton.disabled = false;
            updateStatus('Ready');
        }
    }

    // --- Speech Recognition ---
    function initializeRecognition() {
        if(!('webkitSpeechRecognition' in window)){
            updateStatus('Speech Recognition not supported.', 'text-red-500');
            micButton.disabled=true;
            return;
        }
        recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        recognition.onstart = ()=>{ updateMicButton(true); updateStatus('Listening... Speak now.', 'text-red-500'); };
        recognition.onresult = (event)=>{ const t=event.results[0][0].transcript; updateStatus('Processing...'); getGeminiResponse(t); };
        recognition.onerror = (e)=>{ console.error(e.error); if(e.error!=='no-speech') updateStatus(`Error: ${e.error}`,'text-red-500'); updateMicButton(false); };
        recognition.onend = ()=>{ if(!isAiThinking) updateStatus('Ready'); updateMicButton(false); };
    }

    window.toggleListening = ()=>{ if(isListening) recognition.stop(); else recognition.start(); };

    // --- Speech Synthesis ---
    function speak(text) {
        if(isSpeaking) window.speechSynthesis.cancel();
        isSpeaking = true;
        micButton.disabled=true;
        updateStatus('Gemini is speaking...','text-blue-400');

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate=1;
        utterance.pitch=1;
        utterance.volume=1;

        // Optional: select voice
        // const voices = window.speechSynthesis.getVoices();
        // utterance.voice = voices.find(v=>v.name==='Google US English');

        utterance.onend=()=>{ isSpeaking=false; micButton.disabled=isAiThinking; if(!isAiThinking) updateStatus('Ready'); };
        utterance.onerror=(e)=>{ console.error(e); isSpeaking=false; micButton.disabled=isAiThinking; if(!isAiThinking) updateStatus('Ready'); };

        window.speechSynthesis.speak(utterance);
    }

    document.addEventListener('DOMContentLoaded', ()=>{
        initializeRecognition();
        if(!('speechSynthesis' in window)) updateStatus('TTS not supported. Chat only.','text-orange-400');
        else updateStatus('Ready');
    });
</script>
```

</body>
</html>
